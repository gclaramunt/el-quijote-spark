{"name":"El-quijote-spark","tagline":"Introduction to Spark using \"El Quijote\"","body":"el-quijote-spark\r\n================\r\n\r\n## Introduction to Spark using \"El Quijote\"\r\n(not really big data, but shocases the usefulness of a REPL )\r\n\r\n### Carga el archivo / loads the file\r\n    val texto=sc.textFile(\"el-quijote.txt\")\r\n\r\n#### Cantidad de lineas / line count\r\n    texto.count\r\n\r\n### Primera linea / first line\r\n    texto.first\r\n\r\n### Cantidad de lineas con \"Quijote\" / count of lines containing \"Quijote\"\r\n    texto.filter(line => line.contains(\"Quijote\")).count\r\n\r\n### Cuantas palabras tiene la linea con mas palabras / how many words has the line with most words\r\n    texto.map(line => line.split(\" \").size).reduce((a, b) => if (a > b) a else b)\r\n\r\n### La linea con mas palabaras / get the line with most words \r\n    texto.map(line => (line,line.split(\" \").size)).reduce((a, b) => if (a._2 > b._2) a else b)._1\r\n\r\n### El hello world de big data: conteo de palabras / big data's \"hello world\": word count  \r\n    val wordCounts = texto.flatMap(line => line.split(\" \")).map(word => (word, 1)).reduceByKey(_+_)\r\n\r\n### Array con las primeras 100 entradas / array with the first 100 entries\r\n    wordCounts.take(100)\r\n\r\n### Como no es grande, puedo forzar toda la coleccion a una lista / because is not big, I can force the whole collection to a list\r\n    wordCounts.collect\r\n\r\n#### La palabra mas usada / the most used word\r\n    wordCounts.reduce((a, b) => if (a._2 > b._2) a else b)\r\n\r\n### Top 10\r\n    wordCounts.keyBy(_._2).sortByKey(ascending=false).take(10)\r\n","google":"UA-1731182-4","note":"Don't delete this file! It's used internally to help with page regeneration."}